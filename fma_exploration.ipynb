{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before starting\n",
    "Go to https://github.com/mdeff/fma?tab=readme-ov-file, download the following files:\n",
    "\n",
    "1. `fma_metadata.zip`\n",
    "    - Extract it to `./fma_metadata`\n",
    "2. `fma_small.zip` (Only if you want the audio files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# utils.py, local file\n",
    "import utils\n",
    "\n",
    "from utilities.constants import(\n",
    "    DEFAULT_FMA_METADATA_LOCATION,\n",
    "    FMA_SONG_LOCATION,\n",
    ")\n",
    "\n",
    "# Directory where mp3 are stored\n",
    "AUDIO_DIR = ''\n",
    "\n",
    "# Load metadata and features.\n",
    "base_dir = DEFAULT_FMA_METADATA_LOCATION\n",
    "\n",
    "# these objects are all pandas dataframes\n",
    "tracks = utils.load(f'{base_dir}/tracks.csv')\n",
    "genres = utils.load(f'{base_dir}/genres.csv')\n",
    "features = utils.load(f'{base_dir}/features.csv')\n",
    "echonest = utils.load(f'{base_dir}/echonest.csv')\n",
    "\n",
    "np.testing.assert_array_equal(features.index, tracks.index)\n",
    "assert echonest.index.isin(tracks.index).all()\n",
    "\n",
    "tracks.shape, genres.shape, features.shape, echonest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the columns.\n",
    "# we want to be able to identify which song in the FMA dataset maps to a track ID in the million song subset.\n",
    "tracks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the other notebook so we have the million_song_df in memory here.\n",
    "%run million_song_subset_exploration.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to match the track IDs in the FMA dataset to the track_id in this df:\n",
    "million_song_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so the tracks.index has a weird indexing thing, where you index using the track id.\n",
    "# we want the track id to be a column in the df.\n",
    "# so that when merged, we know which index into 'tracks' (the df) maps to which 'track_id' in million_song_df\n",
    "resetted_tracks = tracks.reset_index()\n",
    "resetted_tracks.rename(columns={'track_id': 'index_into_fma_track_df'}, inplace=True)\n",
    "resetted_tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resetted_tracks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now normalize both dfs: process the strings and find matches between the DFs\n",
    "# extract our desired fma columns\n",
    "\n",
    "fma_tracks = resetted_tracks[[('index_into_fma_track_df', ''), ('track', 'title'), ('artist', 'name')]].copy()\n",
    "fma_tracks.columns = ['index_into_fma_track_df', 'track_title', 'artist_name']\n",
    "\n",
    "# normalize the fma data: lowercase and remove special chars\n",
    "fma_tracks['track_title'] = fma_tracks['track_title'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
    "fma_tracks['artist_name'] = fma_tracks['artist_name'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# normalize text data for Million Song subset the same way\n",
    "million_song_df['track_title'] = million_song_df['track_title'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
    "million_song_df['artist_name'] = million_song_df['artist_name'].str.lower().str.replace('[^\\w\\s]', '', regex=True)\n",
    "\n",
    "# merge DataFrames on 'track_title' and 'artist_name'\n",
    "matched_tracks = pd.merge(million_song_df, fma_tracks, on=['track_title'], how='inner')\n",
    "\n",
    "# results\n",
    "print(matched_tracks.head())\n",
    "print(\"Number of matched tracks:\", matched_tracks.shape[0])\n",
    "\n",
    "matched_tracks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have matched_tracks. Looking at the above cell's output, let's looked at the first matched track. \n",
    "# 'index_into_fma_track_df' == 81912, and the song's name is 'drop of rain'\n",
    "# We have access to the track_id in the million song subset: SOPWKOX12A8C139D43\n",
    "# to access this song in the fma dataset object, we can use the \"index_into_fma_track_df\" value like this:\n",
    "tracks.loc[93986]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "music_recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
